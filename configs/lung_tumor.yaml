# Lung Tumor Segmentation Configuration
# ======================================

# Model Configuration
model:
  type: attention_unet   # Options: unet, attention_unet
  n_channels: 1          # Grayscale CT images
  n_classes: 2           # Background + Tumor
  bilinear: true         # Use bilinear upsampling (vs transposed conv)
  base_features: 64      # Base number of features
  deep_supervision: true # Compute loss at multiple decoder scales

# Data Configuration
data:
  root: ./dataset
  img_size: 512          # Higher resolution for small tumor detection (was 256)
  val_ratio: 0.2         # 20% for validation
  batch_size: 4          # Reduced for 512 input (was 8)
  num_workers: 4

# Training Configuration
train:
  epochs: 400            # Increased for gradient accumulation (8x fewer steps/epoch)
  lr: 0.00005            # Very low constant learning rate
  weight_decay: 0.001    # Stronger L2 regularization
  grad_clip: 1.0         # Gradient clipping (0 to disable)
  accumulation_steps: 8  # Gradient accumulation (effective batch = 4 x 8 = 32)

# Learning Rate Scheduler
scheduler:
  type: reduce_on_plateau  # Use plateau-based reduction instead of warmup
  patience: 30             # More patience (fewer steps per epoch with grad accum)
  factor: 0.5              # LR reduction factor
  min_lr: 0.000001

# EMA (Exponential Moving Average) - Stabilizes training
ema:
  enabled: true            # Use EMA for validation and saving
  decay: 0.99              # Lower decay for faster adaptation
  warmup_epochs: 10        # Use training model for first N epochs

# Early Stopping
early_stopping:
  enabled: true          # Re-enable early stopping
  patience: 50           # More patience for grad accum (fewer updates per epoch)
  monitor: class_dice.tumor  # Monitor TUMOR dice, not mean dice!
  mode: max              # 'max' for metrics, 'min' for loss

# Loss Function
loss:
  type: balanced_focal_tversky  # Balanced CE + Focal Tversky
  balanced_class_weight: 0.5    # Weight for tumor class (0.5 = equal attention)
  ce_weight: 1.0                # Weight for balanced CE component
  dice_weight: 1.0              # Weight for Focal Tversky component
  # Focal Tversky parameters
  tversky_alpha: 0.7            # Weight for false negatives
  tversky_beta: 0.3             # Weight for false positives
  focal_gamma: 0.75             # Focus on hard examples
  # Deep supervision loss weights: [main, 1/2_res, 1/4_res, 1/8_res]
  ds_weights: [1.0, 0.4, 0.2, 0.1]

# Data Augmentation
augmentation:
  enabled: true
  horizontal_flip: 0.5   # Probability
  rotation_limit: 15     # Max rotation angle
  elastic: 0.3           # Elastic deformation probability
  brightness_contrast: 0.3

# Output Configuration
output:
  save_dir: ./runs
  experiment_name: lung_tumor_ds512
  save_last: true        # Save last checkpoint
  save_best: true        # Save best checkpoint

# Reproducibility
seed: 42

# Device
device: ""               # Empty for auto-detect (cuda > mps > cpu)
